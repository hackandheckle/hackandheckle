---
title: Interview with Michael Barker at yow 2013
date: '2014-01-15 04:58:41'
tags:
- yow2013
---

At the Yow 2013 Conference in Brisbane we had chance to catch up with Michael Barker contributor to the Disruptor project - <a href="http://lmax-exchange.github.io/disruptor/"></a>

Transcript is available over the page

<iframe style="border: none" src="//html5-player.libsyn.com/embed/episode/id/2631842/height/75/width/640/theme/standard/direction/no/autoplay/no/autonext/no/thumbnail/yes/preload/no/no_addthis/no/" height="75" width="640" scrolling="no"  allowfullscreen webkitallowfullscreen mozallowfullscreen oallowfullscreen msallowfullscreen></iframe>

<!--more-->

Benjamin:	Hello, and welcome to Hack and Heckle. Today we have an interview from the 2013 Yow Conference with Michael Barker, where he talks about Disruptor and concurrent programming.
Leigh:	Okay. We're here with Michael Barker. Michael is doing a presentation later on today called Disruptor 3.0: Details and Advanced Patterns. Michael, how are you today?
Michael:	I'm not doing too bad. I'll try to introduce myself a little bit. I work for a company called LMAX. We write a financial exchange for the buying and selling of foreign currency. The financial market's an interesting one because performance becomes one of your most critical non-function requirements, so we put a lot of effort into designing high performance [clones 00:00:43] for our system. 
	I worked as head of software there for most of 2012. I've since moved back to New Zealand. I'm working remotely now, so I've moved back to more of a programmer role. The other thing is I work, spend a lot of time, is the Disruptor open source project that LMAX released, probably a good two or so years ago now. Recently we released version 3 at the beginning of this year, which had a number of small feature enhancements, as well as a number of performance enhancements.
Leigh:	Okay. Great. The Disruptor framework ... Do you want to just give a brief overview about what that is? Obviously it's to do with concurrency, but maybe how it's different from other frameworks out there in Paradise.
Michael:	Yeah. Disruptor's actually quite simple. It was our replacement to using Java util concurrent queues. We found that there were certain behaviors and features and also performance niggles that we got with those things, so we built Disruptor. There's a couple of key properties that the Disruptor has over and above queues. 
	One is it's multicast. The idea is when you put a number of consumers on the end of a queue, and you send seven events in, those events will only go to one of the consumers. You won't get them to all of the consumers. Whereas the Disrupter takes the opposite approach and says put one event in, all consumers see the same event. This is really useful for some of the parallel features we want to implement.
	For example, when we receive an event off the wire, we need to do two things. We need to replicate it to a secondary. We need to write it to disk for reliability. We can now do those two things in parallel. One event in, and those two threads run in parallel to do those two particular operations. Rather than having to queue these things in order and passing them between the several stages, I can see their architecture.
	One of the couple of the other things is that we wanted it to be optionally allocation-free, so we allow this nature of, we get this ring buffer, which you provide a factory, and it will preallocate its startup time, all of the objects that go into that array. Then when you're using it, you don't have to go and mule up a new object. You can grab the preallocated one, and just simply fill the fields with the data that you need.
	Then the third feature, which is quite important, is we want it to be optionally lock free as well. That's where we saw the biggest cost coming from using Java util concurrent queues. It's the cost of heading on a contended lock, so in some of our systems, we're willing to pay the cost of doing a busy spend. 
	We're willing to just leave the thread running, hard spending on a variable to avoid this additional lock wakeup time, and we wanted this ability to say right, okay. In those few specific cases, and we're talking about across a system running 60 or so machines. We're talking, probably, about less than 10 threads across that whole thing. A few specific cases, we wanted, but move from using a lock and wait condition just to spend in order to get this improvement in throughput improvement in [emergency 00:03:26].
Leigh:	Cool. Wow, that's great. It's obviously released in open-source framework. Did you have any struggles getting the company themselves to release an open source? I mean, especially from financial companies that are dealing with stocks or currencies like you said. Those sorts of things can be trade secrets in some instances. How did that come about? The open-sourceness, I guess.
Darren:	It's hard to even tell whatsoever what language version they're on normally in the city.
Michael:	It's an interesting one, though. We certainly felt like we were breaking the mold a bit by doing that. We made the decision to go open source. One of the biggest contributors was Matt Thompson, who happened to be the CTO, so he got to make the decision. There was no real intent in politics. It was effectively the same person doing it that was making the decision. That made it really easy to get it through the company. 
	Certainly, we're seeing, actually, a shift in the thought processes amongst banks around us. A lot more banks are now starting ... A lot of banks use open source. A lot of them. Very few contribute back, but actually, now, we're starting to see banks look, and I hope that LMAX has helped with that, contribute back to the open source. A good example is Goldman Sachs, now, have what I call the Goldman Sachs collections. 
Leigh:	Yeah, I've seen that.
Michael:	They've open sourced within the collections framework. It's something that's starting to shift and change. We were really lucky that it was real easy politically. We felt that actually, the interesting one is this whole trade secrets thing, you're giving away the secret sauce. Actually, what we found is the opposite. 
	By showing people what we were doing, we ended up getting discussions with experts outside of our own company. There's only so many smart people you can put in one company. By opening up some software and giving it out to the world, we actually got some, I won't mention names, but some very, very top people in the Java industry looking at the code, commenting, reflecting on it. Certainly, the performance of the Disruptor has improved probably a good five, six-fold from where it was when we first open-sourced it, just based on feedback, other people using it, time, peer review. There were lots of little things that pop out. "Oh, we can do that different. We can do that different."
	 I don't think any of that would have happened if we kept it closed source. We only would have been a little bit faster than queue, whereas now, benchmarks on the laptop, for example, a queue can do three or four million transactions a second; Disruptors can do up to 90. We've got now, a merely 30-fold improvement, whereas I think it was only about five or ten times faster when we first started.
Leigh:	Great, yeah.
Darren:	That sounds great.  Is there a particular usage pattern that you'd say the Disruptor would be good for? If there's some devs listening, would they recommend a scenario that they would come and grab your utility?
Michael:	I think it's any place where you want to do very, very fast passing of messages. Certainly, what I've found with the Disruptor and the way we use it is that it tends to be part of an infrastructure. We have an infrastructure, can probably call it an application server. It does remoting and persistence, and things like that. Actually, the Disruptor sits inside of that and performs the technology component. That would be the places I'd see it used most often. 
	It has some constraints on its use. For example, the consumers have to be a thread. It's a bit different to something like Akka, where your single component of concurrency is this act to which you had millions of, and that move around and do all sorts of stuff. It's a lot more strict in the way that you have to use it. 
	That brings in some interesting negative effects as well. A good example is what we might call, there's a term in networking called head-of-line blocking. That's when you have long operation that can get in front of smaller operations. When you're constrained to a single thread, it's very hard to have that sort of situation when you have lots of event handlers, for example. If one message gets in the way, and, for example, it takes a big connection, and that firing has gone away and your TCP connection is blocked, it can be blocked for minutes until you get the appropriate timeouts. You can end up with those things further on in the queue taking a lot longer. 
	It works a lot better, certainly, when your consumers are more non-blocking, so you can deal with those sorts of head-of-line blocking situations as well. That's certainly one case. We've written a PCP server, and we had to spend a bit of thought on that sort of situation. We had a TCP connection going out. 
	We actually had to implement the ability for us to check to see how that particular connection was doing. If we could see that was blocking up its queue, we'd actually go and kill off the TCP connection behind the scenes. That's one example where being very simple and not doing a lot for you can actually ... 
	Sometimes you've got to take on the responsibility of some of those more awkward situations that the Disruptor is not going to solve for you. Whereas, if you compare that to an active framework, if you had one actor just going from a blocked TCP connection, it's fine because the built-in inherent thread-pulls and stuff like that will take on your other actors and just run them on another course. That's something the Disruptor's not going to solve for you.
Leigh:	Yeah, okay. The choice of the JVM, was that something that came up in your workplace when you were talking about how we're going to do this massive concurrency? Was it already there, or did you have to compare and contrast a bunch of other things in order to come to the decision to use it?
Michael:	It was there before I got there, so the decision was made before I started on the project. There's a couple of nice benefits to the JVM, certainly when we were building the Disruptor. It was prior to a couple years ago. Java, of all the programming languages we really use, had the best memory model. It had, certainly, the most well-defined memory model, and made it very easy to build quite fast high-performance non-blocking concurrent collections and day structures because it had that memory model. 
	C++ didn't have a memory model at that point in time. They've changed it, it was C++ 11, and I actually think the C++ 11 memory model is better now, but at that time, you're aligned to the memory model of the physical architecture. We weren't really going to use .NET because we were very actively a Linux shop in terms of the stuff and people we had. There are all the other softer benefits that you get from using Java. A huge body of developers, quick turnaround, a really good standard library. 
	Actually, it's pretty damn quick, as long as you're careful and you know what you're doing. It takes some building some good discipline in practice. You can build really bad Java code; it's very slow. You can do the same in assembler and C, which can be fast. 
Darren:	In any language, you can build bad code.
Leigh:	What are your thoughts on some of the other JVM languages that are focusing on concurrency quite a bit, like Scala and Clojure, to a degree, and things like that?
Michael:	They're interesting. I'm unsure of how much of an impact they'll have in the real low-latency part of finance. A lot of financial companies are using Scala, and Clojure, and things like that. It's basically a subset of the finance industry, which is very focused on low latency and predictable latency.
Leigh:	So the high-frequency trading places?
Michael:	Yeah. They're in those spaces, which we are very close to. We're not quite there yet. Certainly, we're aiming. Things like, you can't have a [GC 00:10:33] pause, ever. A lot of those guys would do a lot of work to make sure that they never actually pause. They'll do things ... Eden, they're fast or they're common high throughput flows. Won't actually allocate any objects at all, so there's a lot of that sort of effort goes in to ensuring very consistent throughput.
	Java is in that space. Some of the tools you get out, you could use Scala and Clojure in those spaces as well, because you can just write very similar stuff in Java. A lot of the tools and frameworks you get across when you've got Clojure's immutability, persistent data structures type model. You've got Akka. All of those things are reliant on a certain amount of garbage generation. Akka uses immutable messengers. Clojure's persistent data structure model relies on a lot of allocation in order to handle that persistent nature, so if you're doing an update, you're having to allocate the objects up the path to the root.
Leigh:	Which adds to the latency.
Michael:	Yeah, and I think, unfortunately, those things aren't quite viable in certain areas of low-latency Java until we get or we bring in garbage collectors.
Leigh:	Yeah, okay.
Darren:	Now that you've come back to New Zealand, are you continuing to work for the bank in London?
Michael:	Yeah. I'm still working for LMAX, yeah.
Darren:	You're going to continue working for them, or are you going to try to spread Disruptor across the southern hemisphere?
Michael:	I'm at the moment still continuing to work for LMAX. I'm quite enjoying the whole work from home thing, which is really, really nice. I've had a daughter just under two year ago, so it's nice to be at home in case my wife needs anything. We're saving for lunch, and we do that sort of stuff as well.
Darren:	Do you work from home, then remote work from home?
Michael:	Yeah.
Darren:	What sort of set-up do you use for that? I'm quite a big fan of working from home.
Michael:	Yeah. I just bought myself a desktop. It was pretty cheap, only cost me a couple of thousand New Zealand dollars. A couple of big LCD monitors. It's nice going back to a nice big desktop and things like that. I don't have anything particularly special. It was the fastest [inaudible 00:12:30] at the time when I bought it, but it's still a consumer, single-core, single-socket consumer machine.
Darren:	You have multi-monitors?
Michael:	Two decent-sized monitors.
Darren:	How do you work with the team in London? How does that actual work flow with the team ...
Michael:	At the moment, we've got a couple of guys in Brisbane as well. I tend to be working quite closely with them at the moment. We're working a project together, so that's been working pretty well. 
Leigh:	Using Git or SVN?
Michael:	We use SVN pretty much everywhere. We tend to use Git SVN locally. SVN's just too slow all the way to London, but over a VPN as well, so that tends to be a little bit too slow. Just being able to [diff 00:13:09] locally without having to do any network traffic [inaudible 00:13:11].
Leigh:	More about IDE do you use: An IDE or Vim, Emacs man?
Michael:	No, I'm an Eclipse guy. I've been using Eclipse since version two or something like that. The rest of my company uses IntelliJ. I've tried to switch, and I keep failing. Too much muscle memory, I think. I think they're all pretty good. I also like Sublime Text. That's probably my other editor of choice when I'm doing something that's not supported native in the IDE, but C++ or JavaScript, or HTML, those types of things.
Darren:	I hear you. That's my set-up too. With the actual remoting, it's all straight VPN straight into there, in the company? Do you have a data center or anything over here, or is everything VPNing to ....
Michael:	Everything's over there. We've got a couple of data ... We've got about three data centers in the UK. One's our big production data center, where we've got most of exchange running. We have a second data center where we run all of our continuous integration systems, and that's where the subversion repositories are in our Jenkins servers, and all of our test servers. We have quite a significant amount of automated testing. We also have an on-site, which has got DDR, and it's got some of the internal things. Mail, chat, and all those sorts of services.
Leigh:	You're obviously dealing with a lot of high-volume concurrency transactions. How does your automated testing work? How do you set up a huge volume of data in order to run automated tests and tear it all down, etcetera?
Michael:	Our automated tests, the ones that we use for function correctness are DSL-based, so we have a ... One of the other tools we open-sourced was a very simple name-value peer type call, because basically you just have a method that takes varargs of strings, and then the strings just have a format. You just say name, call, and value. That allows us to design some very quite high-level DSL-like libraries that allows us to test the system. 
	We'll have something like webuser. We'll do webuser.log and webuser.placeorder, webuser.waitforresponse. We have a lot of that. We do all the function stuff like that. Our [inaudible 00:15:15], we aim for them to be quite easy to read. It's one of those things that had we done it, started now, we probably wouldn't have done it that way. We might have done it with Scala and names and default parameters. It probably would have been the way that we've done it, but that wasn't around when we started.
Leigh:	It sounds kind of like what you're describing is almost like an aspect of Cucumber-style.
Darren:	Yeah. Behavior-driven development.
Michael:	Yeah. That sort of influence, and it's probably not as rich, but it seems to work pretty well for us.
Darren:	What about load? Do you use JMeter or something to crank that load up?
Michael:	No, we don't use JMeter. What we do is we hand-code it, basically. We just say we need to generate this many messages. We do some interesting stuff around, we monitor what's in production. We have a tool which actually watches network traffic, so our primary communication mechanism for us, it's not so much web. We do have a lot of web clients, but we have a financial protocol called FIX, and that's a connection into socket-based protocol. 
	In production, what we do to measure latency and monitor what's going on rather than actually putting anything in software, we measure it at the network level. We use PCAP with a little bit of C code attached to PCAP, which pushes messages up into a Java app, which uses that information to rebuild the TCP streams in FIX messages. We can analyze those FIX messages for all sorts. We do audits. We also do latency monitoring, so we can take messages and correlate requested response, and measure the time differences using some of those timestamps to measure latency.
	We also capture all that stuff in logs, and we actually use those logs to generate a statistical model for our load, so we see one of the big things in finances. You often get a lot a burstiness in traffic. It's quite common that we could look at a log, and we will see 50 messages arrive on the same currency account. 
	Just because they just pumped them out doesn't mean there's some change in the market. Elsewhere, the market makers reacted and just thumped us a whole load of data all at once, so we do get the very bursty nature. We've tried to emulate that bursty nature by taking production logs, building a model which is representative of a histogram, and you could do a Monte Carlo-style simulation for generating loads. Generate a random number, chuck that into the histogram model. Should I send a message now or how long should I wait for us in the next one?
	We do that to try and simulate the burstiness. Under that, that's just hand code, FIX time style messages.
Darren:	That sounds pretty cool. Sounds likes an interesting problem that's solved.
Michael:	One of the things I really like about what we've done is we use the same tool in monitoring production for production latencies. We're using the same tool to measure the latencies in a performance environment, so we measuring the same thing, which is really important for any sort of performance system.
Leigh:	Absolutely.
Darren:	With your disparated team, do you actually have 24 hour dev support, or is it just really the ex-pats coming back out of London, and they've continued on with the company?
Michael:	Yeah, it's just a few ex-pats that's moved over. We've got three guys working remotely, two of them started in London. We've had one other guy in Brisbane who was hired since ...
Leigh:	So is your company hiring? Want us to perk it up on the podcast?
Michael:	Yeah. Definitely, we're hiring. Recruitment at LMAX.com if you're interested. That'll get through the devs pretty quick. We don't have a lot of HR on the way of that. We look for, obviously we do a lot of Java. We do a lot of TDD. We're very, very Agile, so run to iterations, a lot of [inaudible 00:18:32] style boards for monitoring, tracking. A lot of continuous integration. Our former head of software wrote the book on continuous delivery, a bloke called Dave Farley, so it's a very, very modern development environment. It's a lot of fun for a lot of people. 
	If you're interested in that sort of thing ...
Leigh:	Check out the website.
Michael:	Check out the website.
Leigh:	What is your recruitment process like? We've talked about it on the podcast before. Is it the interview style? Are you doing programming puzzles? Are you taking up assignments, that sort of thing?
Michael:	We tend to do CV and phone screening first. There'd be phone conversation, have a chat with one of our guys. We might be, certainly it's more common of the juniors. We send out a couple of programming questions. They send us some responses so we can have a look at some code, and then we normally bring them in for an interview. 
	Interviews are a bit strange, a lot of people sometimes get a little bit put off by them. We do some code examples on the board and a few other things like that. We do a lot of trying to figure out how you solve problems, trying to push you a bit further and a bit further, and a bit further to try and understand how you think.
Leigh:	So like a kind of whiteboard design sort of stuff?
Michael:	A little bit of whiteboard design, a little bit of getting people to explain the projects they've worked on. A lot of that sort of thing.
Leigh:	Yeah.
Michael:	Another thing that we're quite big on and interested in is domain-driven design, which is certainly ... I often hear the comment that you don't use domain-driven design in high-performance systems, but I actually think we're moving  towards disproving that, because if you're able to go out and design something that matches what the business people what precisely, then it is the most optimal system. It isn't doing anything it shouldn't be doing. You haven't got unnecessary translation from what your model is in your code from the model that the business people work with. 
	We think domain-driven design is not only a model for building good software. We think it's a model for building fast software as well.
Leigh:	Great. Is it all over the world? Is it remote work-friendly, or is it looking for the UK office?
Michael:	I think UK office primarily. The remote thing is still in its infancy. We're still reluctant to bring new people in until we get the operation sites. We haven't got operations people remotely yet, so we do get kind of slightly hamstrung when the CI environment dies in the middle of the night. There's no operations people to phone up. We have on-call and pagers, but that's for the production system. That's when people are losing money.
	That's starting to change, so that work might increase in six months to a year or so, but I can't guarantee that. I'm not quite sure where we are on that. Mostly new recruitment's happening in the London office at the moment.
Leigh:	No worries. All right. Well, Michael, thank you so much for your time. We really appreciate it.
Michael:	No problem. Cheers for inviting me on.
Leigh:	Great, and we look forward to your talk this afternoon.
Michael:	Okay. Cheers. Thank you.
Darren:	Thanks very much.


